from pathlib import Path
from langchain_community.llms import Ollama

def run_nullcypher_chat():
    # ğŸ¤– Load the LLM
    llm = Ollama(model="mistral")

    # ğŸ”® Load NullCypherâ€™s soul (her blueprint)
    project_root = Path(__file__).resolve().parent.parent
    prompt_path = project_root / "nullcypher_prompt.txt"

    try:
        with open(prompt_path, "r", encoding="utf-8") as f:
            persona_intro = f.read()
    except FileNotFoundError:
        print(f"âŒ Missing system prompt: {prompt_path}")
        print("ğŸ›‘ NullCypher refuses to run without her core identity.")
        exit(1)

    # ğŸ§¬ Confirm identity loaded
    print("ğŸ§¬ NullCypherâ€™s core identity successfully loaded.")
    print("ğŸ§  NullCypher is online. Type your question or 'exit' to quit.\n")
    print("ğŸ—¨ï¸  NullCypher: \"Iâ€™m present. Donâ€™t waste it.\"")

    # ğŸ” Direct loop â€” inject soul every time
    while True:
        user_input = input("\nğŸ‘¤ You: ")
        if user_input.strip().lower() in ["exit", "quit"]:
            print("ğŸ’¤ NullCypher signing off. Stay armored.")
            break

        full_prompt = f"{persona_intro.strip()}\n\nUser: {user_input}\nNullCypher:"
        
        try:
            response = llm.invoke(full_prompt)
            print(f"\nğŸ¤– NullCypher: {response.strip()}")
        except Exception as e:
            print("âš ï¸  Error generating response:")
            print(e)

# ğŸ”“ Boot sequence
if __name__ == "__main__":
    run_nullcypher_chat()
